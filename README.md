# ü™Ω Pegasi Feather 
[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/release/python-370/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## ‚ú® Alignment Toolkit

Feather is an alignment framework for protecting LLM responses and aligning Reasoning Language Models (RLMs) like DeepSeek. With Feather, you can simplify reward engineering, evaluations, and guardrails to tailor model behavior and ensure safe, aligned outputs that match your business objectives through Alignment Fine-Tuning (AFT).

- ü§ù Alignment Reward Functions: Central to guiding and optimizing model behavior, ensuring that both the reasoning process and the outputs align with your intended goals.
- üß™ Evaluations: Provide quantitative and qualitative metrics to assess the effectiveness of your alignment strategies, enabling continuous improvement.
- üìö Guardrails: To ensure safe and responsible outputs, prevent harmful or undesirable responses. Enforce strict compliance with business rules. 

## ‚ö° Get Started
1. **Grab your API key here:** [app.pegasi.ai](https://app.pegasi.ai)
2. Quickstart Evals notebook: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1WjV_cqLUN4IDwceFel73OthwSPtuSzu1?usp=sharing#scrollTo=tqij0KeyQMlJ)
3. Alignment-Tuning notebook: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1CaWTfk-D1Oahee3KjUtVnly6Fv_VkM-I?usp=sharing)


## üíº Enterprise Edition
- Domain-specific LLMs as a Judge
- Custom Evaluations
- Robust Reward Engineering Platform
- Ultrafast Customized Guardrails
- Alignment orchestrations
- Automatically adjust model behavior if deviations are detected.
- SSO, Team Management, Auditing
